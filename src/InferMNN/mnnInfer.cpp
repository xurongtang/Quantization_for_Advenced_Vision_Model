// MNNInfer.cpp (ä¿®å¤ç‰ˆ)
#include "mnnInfer.h"
#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp>

MNNInfer::MNNInfer(std::string modelPath,float mean_[3],float std_[3])
    : m_modelPath(modelPath) {
        for(int i = 0; i < 3; i++)
        {
            mnn_mean[i] = mean_[i];
            mnn_std[i] = std_[i];
        }
    }

MNNInfer::~MNNInfer() {
    if (m_session) {
        m_net->releaseSession(m_session);
    }
}

int MNNInfer::loadModel() {
    m_net = std::shared_ptr<MNN::Interpreter>(MNN::Interpreter::createFromFile(m_modelPath.c_str()));
    if (!m_net) {
        std::cerr << "âŒ Failed to load MNN model: " << m_modelPath << std::endl;
        return -1;
    }

    MNN::ScheduleConfig config;
    config.type = MNN_FORWARD_CPU;
    MNN::BackendConfig backendConfig;
    backendConfig.precision = MNN::BackendConfig::Precision_High;
    config.backendConfig = &backendConfig;

    m_session = m_net->createSession(config);
    if (!m_session) {
        std::cerr << "âŒ Failed to create MNN session." << std::endl;
        return -1;
    }

    // è·å–è¾“å…¥å¼ é‡
    auto inputTensors = m_net->getSessionInputAll(m_session);
    if (inputTensors.empty()) {
        std::cerr << "âŒ No input tensor found!" << std::endl;
        return -1;
    }
    std::string inputName = inputTensors.begin()->first;
    m_inputTensor = inputTensors.begin()->second;
    
    if (!m_inputTensor) {
        std::cerr << "âŒ Failed to get input tensor." << std::endl;
        return -1;
    }

    // æ‰“å°è¾“å…¥ä¿¡æ¯
    auto shape = m_inputTensor->shape();
    std::cout << "âœ… Model loaded. Input shape (NCHW): ";
    for (size_t i = 0; i < shape.size(); ++i) {
        std::cout << shape[i] << " ";
    }
    std::cout << std::endl;

    return 0;
}

int MNNInfer::runInference(std::vector<cv::Mat> &inputs, std::vector<std::vector<float>> &outputs) {
    if (!m_session || !m_inputTensor) {
        std::cerr << "âŒ Model not loaded!" << std::endl;
        return -1;
    }
    if (inputs.empty()) {
        std::cerr << "âŒ Input images is empty!" << std::endl;
        return -1;
    }

    auto shape = m_inputTensor->shape();
    int model_batch = shape[0];   // é€šå¸¸æ˜¯ 1
    int channel = shape[1];
    int height = shape[2];
    int width = shape[3];

    // std::cout << "ğŸ“Š Model input shape: " << shape[0] << "x" << shape[1] 
    //           << "x" << shape[2] << "x" << shape[3] << std::endl;

    // âœ… å…³é”®ä¿®æ”¹ï¼šä¸è¦æ£€æŸ¥ batch sizeï¼Œè€Œæ˜¯å¾ªç¯å¤„ç†æ¯ä¸ªè¾“å…¥
    // å³ä½¿ model_batch=1ï¼Œæˆ‘ä»¬ä¹Ÿé€ä¸ªæ¨ç†

    outputs.clear();
    output_shapes.clear();

    // è·å–è¾“å‡º tensor ä¿¡æ¯ï¼ˆå‡è®¾å•è¾“å‡ºï¼‰
    auto outputNames = m_net->getSessionOutputAll(m_session);
    if (outputNames.empty()) {
        std::cerr << "âŒ No output tensor!" << std::endl;
        return -1;
    }
    const std::string& outName = outputNames.begin()->first;

    // é¢„å¤„ç†é…ç½®
    MNN::CV::ImageProcess::Config config;
    config.filterType = MNN::CV::BILINEAR;
    config.sourceFormat = MNN::CV::BGR;
    config.destFormat = MNN::CV::RGB;
    for (int i = 0; i < 3; ++i) {
        config.mean[i]   = mnn_mean[i];
        config.normal[i] = 1.0f / (mnn_std[i] * 255.0f);
    }
    auto process = std::shared_ptr<MNN::CV::ImageProcess>(MNN::CV::ImageProcess::create(config));

    // âœ… é€ä¸ªå¤„ç†æ¯ä¸ªè¾“å…¥å›¾åƒ
    for (size_t i = 0; i < inputs.size(); ++i) {
        cv::Mat& img = inputs[i];
        if (img.empty()) {
            // ç©ºå›¾ï¼šå¡«å……é›¶ç‰¹å¾
            auto outTensor = m_net->getSessionOutput(m_session, outName.c_str());
            size_t feat_dim = 1;
            for (auto s : outTensor->shape()) feat_dim *= s;
            outputs.push_back(std::vector<float>(feat_dim, 0.0f));
            continue;
        }

        // è°ƒæ•´å°ºå¯¸
        cv::Mat resized;
        cv::resize(img, resized, cv::Size(width, height)); // æ³¨æ„ï¼šSize(å®½, é«˜)

        // å‡†å¤‡è¾“å…¥ï¼ˆNCHWï¼Œbatch=1ï¼‰
        MNN::Tensor inputUser(m_inputTensor, MNN::Tensor::CAFFE);
        process->convert(
            resized.data, width, height, width * 3,
            inputUser.host<float>(), width, height
        );
        m_inputTensor->copyFromHostTensor(&inputUser);

        // æ¨ç†
        m_net->runSession(m_session);

        // è·å–è¾“å‡º
        auto outputTensor = m_net->getSessionOutput(m_session, outName.c_str());
        MNN::Tensor outputUser(outputTensor, MNN::Tensor::CAFFE);
        outputTensor->copyToHostTensor(&outputUser);

        auto outShape = outputTensor->shape();
        output_shapes.push_back({outName, outShape});

        size_t total = 1;
        for (auto s : outputTensor->shape()) 
            total *= s;
        std::vector<float> feat(outputUser.host<float>(), outputUser.host<float>() + total);
        outputs.push_back(std::move(feat));
    }

    return 0;
}